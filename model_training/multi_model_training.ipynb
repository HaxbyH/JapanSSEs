{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'EEGNet' from '/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/model_training/EEGNet.py'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import importlib\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import EEGNet as eegnet\n",
    "importlib.reload(eegnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeData(Dataset):\n",
    "    def __init__(self, h_path, d_path):\n",
    "        self.c_path = h_path + d_path\n",
    "        self.h_len = len(h_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.c_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.c_path[idx]\n",
    "\n",
    "        if idx > self.h_len:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 0\n",
    "            \n",
    "        X = np.loadtxt(path, delimiter=',', dtype=str).astype(np.float32)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Undersampling\n",
      "NonSSE: 3306\n",
      "SSE: 2136\n",
      " \n",
      "After Undersampling\n",
      "NonSSE: 2136\n",
      "SSE: 2136\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'area2-detrended'\n",
    "# second_data_directory = 'area2-all'\n",
    "# third_data_directory = 'area3-all'\n",
    "\n",
    "class1_paths = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\" + data_directory + \"/nonSSE/*.csv\")\n",
    "class2_paths = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\"  + data_directory + \"/SSE/*.csv\")\n",
    "\n",
    "# class1_paths_second = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\" + third_data_directory + \"/nonSSE/*.csv\")\n",
    "# class2_paths_second = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\"  + third_data_directory + \"/SSE/*.csv\")\n",
    "\n",
    "# class1_paths = class1_paths + class1_paths_second\n",
    "# class2_paths = class2_paths + class2_paths_second\n",
    "\n",
    "# class1_paths_third = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\" + third_data_directory + \"/nonSSE/*.csv\")\n",
    "# class2_paths_third = glob.glob(\"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/58daysdata/\"  + third_data_directory + \"/SSE/*.csv\")\n",
    "\n",
    "# class1_paths = class1_paths + class1_paths_third\n",
    "# class2_paths = class2_paths + class2_paths_third\n",
    "\n",
    "print(\"Before Undersampling\")\n",
    "print(\"NonSSE:\", len(class1_paths))\n",
    "print(\"SSE:\", len(class2_paths))\n",
    "\n",
    "undersample = True\n",
    "if undersample:\n",
    "    if class1_paths > class2_paths:\n",
    "        sampled = random.sample(range(len(class1_paths)), len(class2_paths))\n",
    "        new_class1_paths = []\n",
    "        for x in sampled:\n",
    "            new_class1_paths.append(class1_paths[x])\n",
    "        class1_paths = new_class1_paths\n",
    "\n",
    "print(\" \")\n",
    "print(\"After Undersampling\")\n",
    "print(\"NonSSE:\", len(class1_paths))\n",
    "print(\"SSE:\", len(class2_paths))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code partitions the code in four sections, for testing on unseen time scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Training\n",
      "SSE: 1512 nonSSE: 1746\n",
      "Validation and Testing\n",
      "SSE: 624 nonSSE: 390\n",
      "\n",
      "Iteration:  1\n",
      "Training\n",
      "SSE: 1664 nonSSE: 1515\n",
      "Validation and Testing\n",
      "SSE: 472 nonSSE: 621\n",
      "\n",
      "Iteration:  2\n",
      "Training\n",
      "SSE: 1594 nonSSE: 1552\n",
      "Validation and Testing\n",
      "SSE: 542 nonSSE: 584\n",
      "\n",
      "Iteration:  3\n",
      "Training\n",
      "SSE: 1638 nonSSE: 1595\n",
      "Validation and Testing\n",
      "SSE: 498 nonSSE: 541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossvalidationsets = []\n",
    "\n",
    "key_dates = [[datetime.datetime(1996, 12, 12), datetime.datetime(2000,9,24)], \n",
    "             [datetime.datetime(2000,9,25), datetime.datetime(2004,7,7)], \n",
    "             [datetime.datetime(2004,7,8), datetime.datetime(2008,4,19)], \n",
    "             [datetime.datetime(2008,4,20), datetime.datetime(2012,1,2)]]\n",
    "\n",
    "# Divide the data into two different sections\n",
    "for x in range(0, len(key_dates)):\n",
    "    sse_train = []\n",
    "    nonsse_train = []\n",
    "    sse_validation = []\n",
    "    nonsse_validation = []\n",
    "\n",
    "    for address in class1_paths:\n",
    "        first_split = address.split(\":\")[0].split(\"/\")\n",
    "        start_date = first_split[len(first_split)-1]\n",
    "        s_date = start_date.split(\"-\")\n",
    "        current_start = datetime.datetime(int(s_date[0]), int(s_date[1]), int(s_date[2]))\n",
    "        if key_dates[x][0] <= current_start <= key_dates[x][1]:\n",
    "            sse_validation.append(address)\n",
    "        else:\n",
    "            sse_train.append(address)\n",
    "\n",
    "    for address in class2_paths:\n",
    "        first_split = address.split(\":\")[0].split(\"/\")\n",
    "        start_date = first_split[len(first_split)-1]\n",
    "        s_date = start_date.split(\"-\")\n",
    "        current_start = datetime.datetime(int(s_date[0]), int(s_date[1]), int(s_date[2]))\n",
    "        if key_dates[x][0] <= current_start <= key_dates[x][1]:\n",
    "            nonsse_validation.append(address)\n",
    "        else:\n",
    "            nonsse_train.append(address)\n",
    "\n",
    "    # Create the training dataset\n",
    "    training_dataset = EarthquakeData(sse_train, nonsse_train)\n",
    "\n",
    "    # Put validation and test data into dataset and split 50/50\n",
    "    validationtest_dataset = EarthquakeData(sse_validation, nonsse_validation)\n",
    "    val_len = len(validationtest_dataset)\n",
    "    train_size = int(val_len * 0.5)\n",
    "    val_size = val_len - train_size\n",
    "    validation_dataset, test_dataset = torch.utils.data.random_split(validationtest_dataset, [val_size, train_size])\n",
    "\n",
    "    # Put everything into array\n",
    "    crossvalidationsets.append([training_dataset, test_dataset, validation_dataset])\n",
    "\n",
    "    print(\"Iteration: \", x)\n",
    "    print(\"Training\")\n",
    "    print(\"SSE: \" + str(len(sse_train)) + \" nonSSE: \" + str(len(nonsse_train)))\n",
    "    print(\"Validation and Testing\")\n",
    "    print(\"SSE: \" + str(len(sse_validation)) + \" nonSSE: \" + str(len(nonsse_validation)))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we train the model 4 times of different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 000: | Train Loss: 0.71606 | Val Loss: 0.71701 | Train Acc: 52.821 | Val Acc: 50.844\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 001: | Train Loss: 0.70814 | Val Loss: 0.72552 | Train Acc: 54.216 | Val Acc: 48.984\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 002: | Train Loss: 0.69539 | Val Loss: 0.74101 | Train Acc: 55.877 | Val Acc: 46.344\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 003: | Train Loss: 0.69517 | Val Loss: 0.74752 | Train Acc: 54.120 | Val Acc: 46.078\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 004: | Train Loss: 0.67787 | Val Loss: 0.76390 | Train Acc: 58.966 | Val Acc: 42.000\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 005: | Train Loss: 0.64256 | Val Loss: 0.79614 | Train Acc: 63.662 | Val Acc: 48.922\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 006: | Train Loss: 0.61332 | Val Loss: 0.88188 | Train Acc: 67.449 | Val Acc: 49.750\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 007: | Train Loss: 0.56926 | Val Loss: 0.86988 | Train Acc: 70.909 | Val Acc: 53.500\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 008: | Train Loss: 0.55992 | Val Loss: 0.87427 | Train Acc: 71.159 | Val Acc: 51.219\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 009: | Train Loss: 0.52999 | Val Loss: 0.84716 | Train Acc: 73.468 | Val Acc: 55.000\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 010: | Train Loss: 0.51926 | Val Loss: 0.83544 | Train Acc: 74.630 | Val Acc: 58.031\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 011: | Train Loss: 0.51020 | Val Loss: 0.94744 | Train Acc: 74.559 | Val Acc: 56.203\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 012: | Train Loss: 0.48552 | Val Loss: 0.85626 | Train Acc: 76.922 | Val Acc: 60.109\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 013: | Train Loss: 0.47397 | Val Loss: 0.87506 | Train Acc: 77.703 | Val Acc: 59.406\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 014: | Train Loss: 0.46759 | Val Loss: 0.85202 | Train Acc: 77.426 | Val Acc: 58.328\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 015: | Train Loss: 0.43899 | Val Loss: 1.00961 | Train Acc: 80.125 | Val Acc: 54.297\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 016: | Train Loss: 0.43308 | Val Loss: 0.96385 | Train Acc: 80.493 | Val Acc: 57.281\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 017: | Train Loss: 0.41491 | Val Loss: 1.09186 | Train Acc: 81.422 | Val Acc: 54.406\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 018: | Train Loss: 0.40038 | Val Loss: 1.05801 | Train Acc: 82.098 | Val Acc: 56.234\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 019: | Train Loss: 0.40117 | Val Loss: 0.98204 | Train Acc: 82.316 | Val Acc: 54.844\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 020: | Train Loss: 0.37712 | Val Loss: 1.12713 | Train Acc: 83.939 | Val Acc: 54.594\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 021: | Train Loss: 0.36747 | Val Loss: 1.14580 | Train Acc: 84.066 | Val Acc: 54.688\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 022: | Train Loss: 0.38613 | Val Loss: 1.21275 | Train Acc: 82.865 | Val Acc: 53.078\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 023: | Train Loss: 0.35947 | Val Loss: 1.20953 | Train Acc: 85.956 | Val Acc: 52.797\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 024: | Train Loss: 0.34610 | Val Loss: 1.26570 | Train Acc: 85.213 | Val Acc: 50.172\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 025: | Train Loss: 0.34313 | Val Loss: 1.35600 | Train Acc: 86.105 | Val Acc: 49.734\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 026: | Train Loss: 0.32677 | Val Loss: 1.53981 | Train Acc: 86.414 | Val Acc: 47.812\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 027: | Train Loss: 0.31993 | Val Loss: 1.52847 | Train Acc: 87.355 | Val Acc: 46.172\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 028: | Train Loss: 0.30823 | Val Loss: 1.37410 | Train Acc: 87.473 | Val Acc: 47.953\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 029: | Train Loss: 0.31508 | Val Loss: 1.50936 | Train Acc: 87.025 | Val Acc: 49.766\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 030: | Train Loss: 0.30118 | Val Loss: 1.54144 | Train Acc: 88.191 | Val Acc: 46.875\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 031: | Train Loss: 0.30382 | Val Loss: 1.51178 | Train Acc: 87.885 | Val Acc: 50.047\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 032: | Train Loss: 0.29664 | Val Loss: 1.61149 | Train Acc: 88.343 | Val Acc: 48.031\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 033: | Train Loss: 0.28584 | Val Loss: 1.45751 | Train Acc: 88.596 | Val Acc: 50.109\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 034: | Train Loss: 0.29136 | Val Loss: 1.61156 | Train Acc: 88.461 | Val Acc: 47.500\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 035: | Train Loss: 0.26729 | Val Loss: 1.82001 | Train Acc: 89.037 | Val Acc: 47.344\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 036: | Train Loss: 0.27070 | Val Loss: 1.52517 | Train Acc: 89.426 | Val Acc: 51.906\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 037: | Train Loss: 0.27095 | Val Loss: 1.63442 | Train Acc: 89.456 | Val Acc: 49.000\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 038: | Train Loss: 0.25727 | Val Loss: 1.80739 | Train Acc: 89.978 | Val Acc: 44.547\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 039: | Train Loss: 0.26786 | Val Loss: 1.79451 | Train Acc: 89.422 | Val Acc: 45.359\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 040: | Train Loss: 0.26801 | Val Loss: 1.86947 | Train Acc: 90.010 | Val Acc: 45.609\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 041: | Train Loss: 0.25762 | Val Loss: 1.99095 | Train Acc: 89.326 | Val Acc: 44.938\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 042: | Train Loss: 0.24365 | Val Loss: 1.82945 | Train Acc: 90.044 | Val Acc: 47.375\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 043: | Train Loss: 0.25571 | Val Loss: 2.12334 | Train Acc: 90.125 | Val Acc: 44.422\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 044: | Train Loss: 0.23328 | Val Loss: 1.95711 | Train Acc: 91.319 | Val Acc: 42.188\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 045: | Train Loss: 0.22985 | Val Loss: 1.96063 | Train Acc: 90.912 | Val Acc: 48.688\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 046: | Train Loss: 0.23978 | Val Loss: 2.02817 | Train Acc: 90.561 | Val Acc: 45.703\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 047: | Train Loss: 0.24924 | Val Loss: 1.86084 | Train Acc: 90.953 | Val Acc: 46.250\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 048: | Train Loss: 0.23820 | Val Loss: 2.28298 | Train Acc: 90.762 | Val Acc: 44.297\n",
      "Iteration: 0 / 408\n",
      "Iteration: 100 / 408\n",
      "Iteration: 200 / 408\n",
      "Iteration: 300 / 408\n",
      "Iteration: 400 / 408\n",
      "Epoch 049: | Train Loss: 0.22464 | Val Loss: 1.88741 | Train Acc: 91.167 | Val Acc: 46.906\n",
      "Testing Accuracy:  54.625\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 000: | Train Loss: 0.70729 | Val Loss: 0.74707 | Train Acc: 54.570 | Val Acc: 46.058\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 001: | Train Loss: 0.69656 | Val Loss: 0.76530 | Train Acc: 54.053 | Val Acc: 45.710\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 002: | Train Loss: 0.68910 | Val Loss: 0.73736 | Train Acc: 56.817 | Val Acc: 50.783\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 003: | Train Loss: 0.68626 | Val Loss: 0.75644 | Train Acc: 57.332 | Val Acc: 47.565\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 004: | Train Loss: 0.68795 | Val Loss: 0.74994 | Train Acc: 56.510 | Val Acc: 48.174\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 005: | Train Loss: 0.67931 | Val Loss: 0.75047 | Train Acc: 57.646 | Val Acc: 47.101\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 006: | Train Loss: 0.66875 | Val Loss: 0.72710 | Train Acc: 61.254 | Val Acc: 47.333\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 007: | Train Loss: 0.65160 | Val Loss: 0.76141 | Train Acc: 62.435 | Val Acc: 46.261\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 008: | Train Loss: 0.61926 | Val Loss: 0.80958 | Train Acc: 65.884 | Val Acc: 49.348\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 009: | Train Loss: 0.57807 | Val Loss: 0.79426 | Train Acc: 69.181 | Val Acc: 52.290\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 010: | Train Loss: 0.56079 | Val Loss: 0.82106 | Train Acc: 71.837 | Val Acc: 53.522\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 011: | Train Loss: 0.53777 | Val Loss: 0.88451 | Train Acc: 73.239 | Val Acc: 52.304\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 012: | Train Loss: 0.53293 | Val Loss: 0.78443 | Train Acc: 73.799 | Val Acc: 57.246\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 013: | Train Loss: 0.51788 | Val Loss: 0.80957 | Train Acc: 74.834 | Val Acc: 54.116\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 014: | Train Loss: 0.49707 | Val Loss: 0.82364 | Train Acc: 76.377 | Val Acc: 56.304\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 015: | Train Loss: 0.47837 | Val Loss: 0.85901 | Train Acc: 78.312 | Val Acc: 57.348\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 016: | Train Loss: 0.47554 | Val Loss: 0.95645 | Train Acc: 76.955 | Val Acc: 52.348\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 017: | Train Loss: 0.45457 | Val Loss: 0.93358 | Train Acc: 78.736 | Val Acc: 57.725\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 018: | Train Loss: 0.43258 | Val Loss: 0.94607 | Train Acc: 79.827 | Val Acc: 55.971\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 019: | Train Loss: 0.41880 | Val Loss: 1.10348 | Train Acc: 80.832 | Val Acc: 51.739\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 020: | Train Loss: 0.40575 | Val Loss: 1.07536 | Train Acc: 82.239 | Val Acc: 55.145\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 021: | Train Loss: 0.40255 | Val Loss: 1.11063 | Train Acc: 82.103 | Val Acc: 52.130\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 022: | Train Loss: 0.38226 | Val Loss: 1.13492 | Train Acc: 83.196 | Val Acc: 53.101\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 023: | Train Loss: 0.39457 | Val Loss: 1.09729 | Train Acc: 83.103 | Val Acc: 56.391\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 024: | Train Loss: 0.35829 | Val Loss: 1.29164 | Train Acc: 84.425 | Val Acc: 53.594\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 025: | Train Loss: 0.36315 | Val Loss: 1.26233 | Train Acc: 84.226 | Val Acc: 53.855\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 026: | Train Loss: 0.34346 | Val Loss: 1.30024 | Train Acc: 85.015 | Val Acc: 51.623\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 027: | Train Loss: 0.34343 | Val Loss: 1.47286 | Train Acc: 85.927 | Val Acc: 50.174\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 028: | Train Loss: 0.33255 | Val Loss: 1.45396 | Train Acc: 86.106 | Val Acc: 51.638\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 029: | Train Loss: 0.33699 | Val Loss: 1.42185 | Train Acc: 85.849 | Val Acc: 52.841\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 030: | Train Loss: 0.32011 | Val Loss: 1.48889 | Train Acc: 87.495 | Val Acc: 49.739\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 031: | Train Loss: 0.32137 | Val Loss: 1.54212 | Train Acc: 86.839 | Val Acc: 49.812\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 032: | Train Loss: 0.31781 | Val Loss: 1.44260 | Train Acc: 87.251 | Val Acc: 49.014\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 033: | Train Loss: 0.31815 | Val Loss: 1.60574 | Train Acc: 86.925 | Val Acc: 46.870\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 034: | Train Loss: 0.31986 | Val Loss: 1.37631 | Train Acc: 86.967 | Val Acc: 52.333\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 035: | Train Loss: 0.30042 | Val Loss: 1.48739 | Train Acc: 87.930 | Val Acc: 49.029\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 036: | Train Loss: 0.30634 | Val Loss: 1.58223 | Train Acc: 87.656 | Val Acc: 49.667\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 037: | Train Loss: 0.30305 | Val Loss: 1.61077 | Train Acc: 87.799 | Val Acc: 48.783\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 038: | Train Loss: 0.30978 | Val Loss: 1.55943 | Train Acc: 87.244 | Val Acc: 51.507\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 039: | Train Loss: 0.27598 | Val Loss: 2.01378 | Train Acc: 89.342 | Val Acc: 46.087\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 040: | Train Loss: 0.29399 | Val Loss: 1.69430 | Train Acc: 88.440 | Val Acc: 50.623\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 041: | Train Loss: 0.31049 | Val Loss: 1.72337 | Train Acc: 86.608 | Val Acc: 50.014\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 042: | Train Loss: 0.27447 | Val Loss: 1.74490 | Train Acc: 89.168 | Val Acc: 48.681\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 043: | Train Loss: 0.29537 | Val Loss: 1.60708 | Train Acc: 88.508 | Val Acc: 52.435\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 044: | Train Loss: 0.28865 | Val Loss: 1.71664 | Train Acc: 87.759 | Val Acc: 48.899\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 045: | Train Loss: 0.27195 | Val Loss: 1.83167 | Train Acc: 89.430 | Val Acc: 51.420\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 046: | Train Loss: 0.27159 | Val Loss: 1.76634 | Train Acc: 88.864 | Val Acc: 48.014\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 047: | Train Loss: 0.26166 | Val Loss: 1.95042 | Train Acc: 89.666 | Val Acc: 49.681\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 048: | Train Loss: 0.28834 | Val Loss: 1.97622 | Train Acc: 87.980 | Val Acc: 47.638\n",
      "Iteration: 0 / 398\n",
      "Iteration: 100 / 398\n",
      "Iteration: 200 / 398\n",
      "Iteration: 300 / 398\n",
      "Epoch 049: | Train Loss: 0.27172 | Val Loss: 1.71906 | Train Acc: 88.899 | Val Acc: 52.551\n",
      "Testing Accuracy:  56.05797101449275\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 000: | Train Loss: 0.70095 | Val Loss: 0.76270 | Train Acc: 55.972 | Val Acc: 44.465\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 001: | Train Loss: 0.68131 | Val Loss: 0.80162 | Train Acc: 57.992 | Val Acc: 44.028\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 002: | Train Loss: 0.67423 | Val Loss: 0.74250 | Train Acc: 59.782 | Val Acc: 49.056\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 003: | Train Loss: 0.66626 | Val Loss: 0.82779 | Train Acc: 60.662 | Val Acc: 39.986\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 004: | Train Loss: 0.64868 | Val Loss: 0.81014 | Train Acc: 62.190 | Val Acc: 43.070\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 005: | Train Loss: 0.65442 | Val Loss: 0.77777 | Train Acc: 62.259 | Val Acc: 47.423\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 006: | Train Loss: 0.63982 | Val Loss: 0.79444 | Train Acc: 63.599 | Val Acc: 45.662\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 007: | Train Loss: 0.64025 | Val Loss: 0.84262 | Train Acc: 63.769 | Val Acc: 47.873\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 008: | Train Loss: 0.61523 | Val Loss: 0.78174 | Train Acc: 66.596 | Val Acc: 51.366\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 009: | Train Loss: 0.60175 | Val Loss: 0.79474 | Train Acc: 66.746 | Val Acc: 52.099\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 010: | Train Loss: 0.59017 | Val Loss: 0.80496 | Train Acc: 69.307 | Val Acc: 50.606\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 011: | Train Loss: 0.56723 | Val Loss: 0.89938 | Train Acc: 69.794 | Val Acc: 46.972\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 012: | Train Loss: 0.54321 | Val Loss: 0.88719 | Train Acc: 71.990 | Val Acc: 51.620\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 013: | Train Loss: 0.51233 | Val Loss: 0.95121 | Train Acc: 75.142 | Val Acc: 50.183\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 014: | Train Loss: 0.52899 | Val Loss: 1.02138 | Train Acc: 73.896 | Val Acc: 46.127\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 015: | Train Loss: 0.49679 | Val Loss: 0.87729 | Train Acc: 75.975 | Val Acc: 53.704\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 016: | Train Loss: 0.50513 | Val Loss: 1.01514 | Train Acc: 74.640 | Val Acc: 51.789\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 017: | Train Loss: 0.48202 | Val Loss: 1.01118 | Train Acc: 77.505 | Val Acc: 49.972\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 018: | Train Loss: 0.46994 | Val Loss: 1.00823 | Train Acc: 77.721 | Val Acc: 51.521\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 019: | Train Loss: 0.46755 | Val Loss: 0.94215 | Train Acc: 76.977 | Val Acc: 52.789\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 020: | Train Loss: 0.45837 | Val Loss: 0.91967 | Train Acc: 78.589 | Val Acc: 54.070\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 021: | Train Loss: 0.43520 | Val Loss: 0.99862 | Train Acc: 79.662 | Val Acc: 54.352\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 022: | Train Loss: 0.45150 | Val Loss: 0.97804 | Train Acc: 79.107 | Val Acc: 52.141\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 023: | Train Loss: 0.42690 | Val Loss: 1.08046 | Train Acc: 80.426 | Val Acc: 51.380\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 024: | Train Loss: 0.42077 | Val Loss: 0.97814 | Train Acc: 80.827 | Val Acc: 55.113\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 025: | Train Loss: 0.42564 | Val Loss: 1.07822 | Train Acc: 80.173 | Val Acc: 51.986\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 026: | Train Loss: 0.40571 | Val Loss: 1.06633 | Train Acc: 81.845 | Val Acc: 55.239\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 027: | Train Loss: 0.39868 | Val Loss: 1.10080 | Train Acc: 81.452 | Val Acc: 54.845\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 028: | Train Loss: 0.38282 | Val Loss: 1.05169 | Train Acc: 83.086 | Val Acc: 52.239\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 029: | Train Loss: 0.39055 | Val Loss: 1.13284 | Train Acc: 83.365 | Val Acc: 53.282\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 030: | Train Loss: 0.38117 | Val Loss: 1.15477 | Train Acc: 84.168 | Val Acc: 52.197\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 031: | Train Loss: 0.38402 | Val Loss: 1.09258 | Train Acc: 83.622 | Val Acc: 55.408\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 032: | Train Loss: 0.36790 | Val Loss: 1.19949 | Train Acc: 84.003 | Val Acc: 53.296\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 033: | Train Loss: 0.37794 | Val Loss: 1.14001 | Train Acc: 83.449 | Val Acc: 53.014\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 034: | Train Loss: 0.35122 | Val Loss: 1.18584 | Train Acc: 84.528 | Val Acc: 52.211\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 035: | Train Loss: 0.34459 | Val Loss: 1.19156 | Train Acc: 85.137 | Val Acc: 52.577\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 036: | Train Loss: 0.34579 | Val Loss: 1.26726 | Train Acc: 85.168 | Val Acc: 52.366\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 037: | Train Loss: 0.32242 | Val Loss: 1.22225 | Train Acc: 86.236 | Val Acc: 54.197\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 038: | Train Loss: 0.34948 | Val Loss: 1.24445 | Train Acc: 85.734 | Val Acc: 53.521\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 039: | Train Loss: 0.33860 | Val Loss: 1.30355 | Train Acc: 85.967 | Val Acc: 52.141\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 040: | Train Loss: 0.30507 | Val Loss: 1.18854 | Train Acc: 86.404 | Val Acc: 56.958\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 041: | Train Loss: 0.32994 | Val Loss: 1.27993 | Train Acc: 86.317 | Val Acc: 51.901\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 042: | Train Loss: 0.28547 | Val Loss: 1.17787 | Train Acc: 88.122 | Val Acc: 58.169\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 043: | Train Loss: 0.31505 | Val Loss: 1.34366 | Train Acc: 86.363 | Val Acc: 51.366\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 044: | Train Loss: 0.29642 | Val Loss: 1.30976 | Train Acc: 87.299 | Val Acc: 56.141\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 045: | Train Loss: 0.28943 | Val Loss: 1.62745 | Train Acc: 87.622 | Val Acc: 49.958\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 046: | Train Loss: 0.27671 | Val Loss: 1.35190 | Train Acc: 89.056 | Val Acc: 55.366\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 047: | Train Loss: 0.29349 | Val Loss: 1.26155 | Train Acc: 87.624 | Val Acc: 53.155\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 048: | Train Loss: 0.27182 | Val Loss: 1.40962 | Train Acc: 88.972 | Val Acc: 52.493\n",
      "Iteration: 0 / 394\n",
      "Iteration: 100 / 394\n",
      "Iteration: 200 / 394\n",
      "Iteration: 300 / 394\n",
      "Epoch 049: | Train Loss: 0.27335 | Val Loss: 1.42281 | Train Acc: 89.058 | Val Acc: 54.296\n",
      "Testing Accuracy:  53.394366197183096\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 000: | Train Loss: 0.71044 | Val Loss: 0.67836 | Train Acc: 54.264 | Val Acc: 58.338\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 001: | Train Loss: 0.68553 | Val Loss: 0.68916 | Train Acc: 58.652 | Val Acc: 52.185\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 002: | Train Loss: 0.68297 | Val Loss: 0.67611 | Train Acc: 58.896 | Val Acc: 58.123\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 003: | Train Loss: 0.66936 | Val Loss: 0.66798 | Train Acc: 60.681 | Val Acc: 56.231\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 004: | Train Loss: 0.66806 | Val Loss: 0.66969 | Train Acc: 61.304 | Val Acc: 60.215\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 005: | Train Loss: 0.64387 | Val Loss: 0.67707 | Train Acc: 63.521 | Val Acc: 57.569\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 006: | Train Loss: 0.61335 | Val Loss: 0.70801 | Train Acc: 67.923 | Val Acc: 55.477\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 007: | Train Loss: 0.57766 | Val Loss: 0.74386 | Train Acc: 69.854 | Val Acc: 57.554\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 008: | Train Loss: 0.54055 | Val Loss: 0.87680 | Train Acc: 73.111 | Val Acc: 50.092\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 009: | Train Loss: 0.51760 | Val Loss: 0.82317 | Train Acc: 75.649 | Val Acc: 56.554\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 010: | Train Loss: 0.49258 | Val Loss: 0.80851 | Train Acc: 75.758 | Val Acc: 58.369\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 011: | Train Loss: 0.48549 | Val Loss: 0.80843 | Train Acc: 77.136 | Val Acc: 55.800\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 012: | Train Loss: 0.47254 | Val Loss: 0.86127 | Train Acc: 78.025 | Val Acc: 56.077\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 013: | Train Loss: 0.46103 | Val Loss: 0.84825 | Train Acc: 78.815 | Val Acc: 58.754\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 014: | Train Loss: 0.44903 | Val Loss: 0.89093 | Train Acc: 79.879 | Val Acc: 58.292\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 015: | Train Loss: 0.44253 | Val Loss: 0.84702 | Train Acc: 79.516 | Val Acc: 61.585\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 016: | Train Loss: 0.42474 | Val Loss: 0.92037 | Train Acc: 81.684 | Val Acc: 55.046\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 017: | Train Loss: 0.42990 | Val Loss: 0.91500 | Train Acc: 81.119 | Val Acc: 58.754\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 018: | Train Loss: 0.41155 | Val Loss: 0.90924 | Train Acc: 81.825 | Val Acc: 55.831\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 019: | Train Loss: 0.40407 | Val Loss: 0.90810 | Train Acc: 82.523 | Val Acc: 60.031\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 020: | Train Loss: 0.40050 | Val Loss: 0.97773 | Train Acc: 83.005 | Val Acc: 58.892\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 021: | Train Loss: 0.37815 | Val Loss: 0.87348 | Train Acc: 83.521 | Val Acc: 62.954\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 022: | Train Loss: 0.38224 | Val Loss: 1.13005 | Train Acc: 83.531 | Val Acc: 54.308\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 023: | Train Loss: 0.35940 | Val Loss: 1.04377 | Train Acc: 84.815 | Val Acc: 57.138\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 024: | Train Loss: 0.36306 | Val Loss: 0.98627 | Train Acc: 85.348 | Val Acc: 58.954\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 025: | Train Loss: 0.33563 | Val Loss: 1.15969 | Train Acc: 86.126 | Val Acc: 57.385\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 026: | Train Loss: 0.34290 | Val Loss: 1.08563 | Train Acc: 86.109 | Val Acc: 58.938\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 027: | Train Loss: 0.33149 | Val Loss: 1.13713 | Train Acc: 85.640 | Val Acc: 58.092\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 028: | Train Loss: 0.33140 | Val Loss: 1.08703 | Train Acc: 86.094 | Val Acc: 61.400\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 029: | Train Loss: 0.32010 | Val Loss: 1.25386 | Train Acc: 86.580 | Val Acc: 61.185\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 030: | Train Loss: 0.31918 | Val Loss: 1.08070 | Train Acc: 87.365 | Val Acc: 58.677\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 031: | Train Loss: 0.30194 | Val Loss: 1.30531 | Train Acc: 87.765 | Val Acc: 59.615\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 032: | Train Loss: 0.29315 | Val Loss: 1.03188 | Train Acc: 88.178 | Val Acc: 63.538\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 033: | Train Loss: 0.27908 | Val Loss: 1.22092 | Train Acc: 89.077 | Val Acc: 59.523\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 034: | Train Loss: 0.28525 | Val Loss: 1.27860 | Train Acc: 88.654 | Val Acc: 60.046\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 035: | Train Loss: 0.29214 | Val Loss: 1.07858 | Train Acc: 87.640 | Val Acc: 60.215\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 036: | Train Loss: 0.30473 | Val Loss: 1.15624 | Train Acc: 87.926 | Val Acc: 62.138\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 037: | Train Loss: 0.27261 | Val Loss: 1.27793 | Train Acc: 89.748 | Val Acc: 62.154\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 038: | Train Loss: 0.26098 | Val Loss: 1.25118 | Train Acc: 89.881 | Val Acc: 60.846\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 039: | Train Loss: 0.25989 | Val Loss: 1.15376 | Train Acc: 90.240 | Val Acc: 63.862\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 040: | Train Loss: 0.25748 | Val Loss: 1.27367 | Train Acc: 90.225 | Val Acc: 60.831\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 041: | Train Loss: 0.26422 | Val Loss: 1.25143 | Train Acc: 89.837 | Val Acc: 60.492\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 042: | Train Loss: 0.25463 | Val Loss: 1.19704 | Train Acc: 89.425 | Val Acc: 62.169\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 043: | Train Loss: 0.26031 | Val Loss: 1.20343 | Train Acc: 89.590 | Val Acc: 60.246\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 044: | Train Loss: 0.25809 | Val Loss: 1.14997 | Train Acc: 89.677 | Val Acc: 60.815\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 045: | Train Loss: 0.25847 | Val Loss: 1.29081 | Train Acc: 89.279 | Val Acc: 60.400\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 046: | Train Loss: 0.24391 | Val Loss: 1.42955 | Train Acc: 90.815 | Val Acc: 58.323\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 047: | Train Loss: 0.24175 | Val Loss: 1.15615 | Train Acc: 90.360 | Val Acc: 62.369\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 048: | Train Loss: 0.23765 | Val Loss: 1.37699 | Train Acc: 90.462 | Val Acc: 59.877\n",
      "Iteration: 0 / 405\n",
      "Iteration: 100 / 405\n",
      "Iteration: 200 / 405\n",
      "Iteration: 300 / 405\n",
      "Iteration: 400 / 405\n",
      "Epoch 049: | Train Loss: 0.24881 | Val Loss: 1.25429 | Train Acc: 90.326 | Val Acc: 57.523\n",
      "Testing Accuracy:  60.96923076923077\n"
     ]
    }
   ],
   "source": [
    "statistics = []\n",
    "\n",
    "for datasets in crossvalidationsets:\n",
    "    \n",
    "    # Creates training, validation, and test data for each training dataset\n",
    "    batch_size = 8\n",
    "    dataloader = DataLoader(datasets[0], batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(datasets[1], batch_size, shuffle=True)\n",
    "    validation_dataloader = DataLoader(datasets[2], batch_size, shuffle=True)\n",
    "\n",
    "    # Sets up the parameters of the model\n",
    "    num_chans = 30\n",
    "    model = eegnet.EEGNet(Chans = num_chans, Samples = 128, nb_classes=1, kernLength=5).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Set Epochs and train the model\n",
    "    epochs = 50\n",
    "    best_weights, accuracy_stats, loss_stats = eegnet.train(model, optimizer, criterion, dataloader, \n",
    "                                                    validation_dataloader, epochs=epochs, device=device)\n",
    "    \n",
    "    # Load in best weights for the model for testing\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Grab the testing score of the model\n",
    "    test_acc = 0\n",
    "    for test_features, test_labels in test_dataloader:\n",
    "\n",
    "        test_features, test_labels = test_features.to(device), test_labels.to(device)\n",
    "        test_features = test_features.float()\n",
    "        test_labels = test_labels.float()\n",
    "        \n",
    "        test_pred = model(test_features)\n",
    "        test_pred = torch.squeeze(test_pred)\n",
    "        test_acc_item = eegnet.binary_acc(test_pred, test_labels)\n",
    "        test_acc += test_acc_item.item()\n",
    "    \n",
    "    final_test_acc = test_acc/len(test_dataloader)\n",
    "    print(\"Testing Accuracy: \", final_test_acc)\n",
    "\n",
    "    statistics.append([best_weights, accuracy_stats, loss_stats, final_test_acc, model])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the statistics of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tested = \"area2-detrended/\"\n",
    "file_names = ['first', \"second\", \"third\", \"fourth\"]\n",
    "\n",
    "directory_path = \"/Users/haxby/Desktop/Earthquakes/gnss-sse-detection-main/cross_validation_results/\"\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "directory_path = directory_path + model_tested\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "# add the statistics to each file\n",
    "for i, dir_name in enumerate(file_names):\n",
    "    final_path = directory_path + dir_name + \"/\"\n",
    "\n",
    "    if not os.path.exists(final_path):\n",
    "        os.makedirs(final_path)\n",
    "    \n",
    "    # Accuracy Scores\n",
    "    scores_file = open(final_path + \"accuracy_scores.txt\", 'w')\n",
    "    scores_file.write(\"Testing Score: \" + str(statistics[i][3]) + \"\\n\")\n",
    "    scores_file.close()\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(statistics[i][4].state_dict(), final_path+\"saved_model.pth\")\n",
    "\n",
    "    # Save Accuracy Statistics\n",
    "    acc_file = open(final_path + \"accuracy_stats.obj\", 'wb')\n",
    "    pickle.dump(statistics[i][1], acc_file)\n",
    "    acc_file.close()\n",
    "\n",
    "    loss_file = open(final_path+\"loss_stats.obj\", 'wb')\n",
    "    pickle.dump(statistics[i][2], loss_file)\n",
    "    loss_file.close()\n",
    "\n",
    "    b_weights_file = open(final_path+\"best_weights.obj\", \"wb\")\n",
    "    pickle.dump(statistics[i][0], b_weights_file)\n",
    "    b_weights_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3701c2ec140a6f890c79e4c3d9e47dded07056a87bb2a26537bb192f69fdce6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
